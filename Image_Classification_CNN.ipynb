{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Butterfly Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data exploration, Preprocessing and Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename                     label\n",
      "0  train/Image_1.jpg          SOUTHERN DOGFACE\n",
      "1  train/Image_2.jpg                    ADONIS\n",
      "2  train/Image_3.jpg            BROWN SIPROETA\n",
      "3  train/Image_4.jpg                   MONARCH\n",
      "4  train/Image_5.jpg  GREEN CELLED CATTLEHEART\n",
      "0 <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224 at 0x24A0EBF9DD0> SOUTHERN DOGFACE\n",
      "<PIL.Image.Image image mode=RGB size=128x128 at 0x24A155A2690> SOUTHERN DOGFACE\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "train_df = pd.read_csv('Training_set.csv')\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(train_df.head())\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        label = row['label']\n",
    "        img = Image.open(filename)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels\n",
    "train_images, train_labels = load_images(train_df)\n",
    "print(\"0\", train_images[0], train_labels[0])\n",
    "\n",
    "# Example of resizing images\n",
    "def preprocess_images(images, size=(128, 128)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = img.resize(size)\n",
    "        processed_images.append(img)\n",
    "    return processed_images\n",
    "\n",
    "# Example usage\n",
    "train_images_resized = preprocess_images(train_images)\n",
    "print(train_images_resized[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADONIS': 0, 'AFRICAN GIANT SWALLOWTAIL': 1, 'AMERICAN SNOOT': 2, 'AN 88': 3, 'APPOLLO': 4, 'ATALA': 5, 'BANDED ORANGE HELICONIAN': 6, 'BANDED PEACOCK': 7, 'BECKERS WHITE': 8, 'BLACK HAIRSTREAK': 9, 'BLUE MORPHO': 10, 'BLUE SPOTTED CROW': 11, 'BROWN SIPROETA': 12, 'CABBAGE WHITE': 13, 'CAIRNS BIRDWING': 14, 'CHECQUERED SKIPPER': 15, 'CHESTNUT': 16, 'CLEOPATRA': 17, 'CLODIUS PARNASSIAN': 18, 'CLOUDED SULPHUR': 19, 'COMMON BANDED AWL': 20, 'COMMON WOOD-NYMPH': 21, 'COPPER TAIL': 22, 'CRECENT': 23, 'CRIMSON PATCH': 24, 'DANAID EGGFLY': 25, 'EASTERN COMA': 26, 'EASTERN DAPPLE WHITE': 27, 'EASTERN PINE ELFIN': 28, 'ELBOWED PIERROT': 29, 'GOLD BANDED': 30, 'GREAT EGGFLY': 31, 'GREAT JAY': 32, 'GREEN CELLED CATTLEHEART': 33, 'GREY HAIRSTREAK': 34, 'INDRA SWALLOW': 35, 'IPHICLUS SISTER': 36, 'JULIA': 37, 'LARGE MARBLE': 38, 'MALACHITE': 39, 'MANGROVE SKIPPER': 40, 'MESTRA': 41, 'METALMARK': 42, 'MILBERTS TORTOISESHELL': 43, 'MONARCH': 44, 'MOURNING CLOAK': 45, 'ORANGE OAKLEAF': 46, 'ORANGE TIP': 47, 'ORCHARD SWALLOW': 48, 'PAINTED LADY': 49, 'PAPER KITE': 50, 'PEACOCK': 51, 'PINE WHITE': 52, 'PIPEVINE SWALLOW': 53, 'POPINJAY': 54, 'PURPLE HAIRSTREAK': 55, 'PURPLISH COPPER': 56, 'QUESTION MARK': 57, 'RED ADMIRAL': 58, 'RED CRACKER': 59, 'RED POSTMAN': 60, 'RED SPOTTED PURPLE': 61, 'SCARCE SWALLOW': 62, 'SILVER SPOT SKIPPER': 63, 'SLEEPY ORANGE': 64, 'SOOTYWING': 65, 'SOUTHERN DOGFACE': 66, 'STRAITED QUEEN': 67, 'TROPICAL LEAFWING': 68, 'TWO BARRED FLASHER': 69, 'ULYSES': 70, 'VICEROY': 71, 'WOOD SATYR': 72, 'YELLOW SWALLOW TAIL': 73, 'ZEBRA LONG WING': 74}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels to numeric values\n",
    "numeric_labels = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Show the unique labels and their corresponding numeric values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        label = row['label']\n",
    "        try:\n",
    "            img = Image.open(filename)\n",
    "            img = img.resize((128, 128))  # Resize to a fixed size\n",
    "            images.append(np.array(img))  # Convert image to numpy array\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {filename}. Error: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels\n",
    "train_images, train_labels = load_images(train_df)\n",
    "\n",
    "# Convert images to numpy array for further processing\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "# Encode labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_labels = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Convert numeric labels to one-hot encoded labels\n",
    "one_hot_labels = to_categorical(numeric_labels)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, one_hot_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to [0, 1] range\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 75)                9675      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3314315 (12.64 MB)\n",
      "Trainable params: 3314315 (12.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(75, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "163/163 [==============================] - 26s 151ms/step - loss: 4.0355 - accuracy: 0.0556 - val_loss: 3.4347 - val_accuracy: 0.1985\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 25s 152ms/step - loss: 3.1667 - accuracy: 0.2012 - val_loss: 2.5743 - val_accuracy: 0.3469\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 2.5115 - accuracy: 0.3316 - val_loss: 2.1774 - val_accuracy: 0.4377\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 23s 144ms/step - loss: 2.0470 - accuracy: 0.4374 - val_loss: 1.8923 - val_accuracy: 0.4931\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 23s 138ms/step - loss: 1.6745 - accuracy: 0.5209 - val_loss: 1.8033 - val_accuracy: 0.5069\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 24s 146ms/step - loss: 1.3886 - accuracy: 0.5965 - val_loss: 1.6709 - val_accuracy: 0.5446\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 24s 146ms/step - loss: 1.1878 - accuracy: 0.6478 - val_loss: 1.6776 - val_accuracy: 0.5531\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 23s 144ms/step - loss: 0.9962 - accuracy: 0.6940 - val_loss: 1.6861 - val_accuracy: 0.5654\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 23s 144ms/step - loss: 0.8694 - accuracy: 0.7307 - val_loss: 1.6833 - val_accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 24s 145ms/step - loss: 0.7543 - accuracy: 0.7661 - val_loss: 1.7582 - val_accuracy: 0.5592\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 1.7582 - accuracy: 0.5592\n",
      "Validation Loss: 1.7582179307937622\n",
      "Validation Accuracy: 0.5592307448387146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ssemi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "# Save the model\n",
    "model.save('butterfly_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file 'butterfly_classifier_model.h5' exists.\n",
      "Model loaded successfully.\n",
      "88/88 [==============================] - 3s 36ms/step\n",
      "           filename                   label\n",
      "0  test/Image_1.jpg              PINE WHITE\n",
      "1  test/Image_2.jpg           CRIMSON PATCH\n",
      "2  test/Image_3.jpg                  ADONIS\n",
      "3  test/Image_4.jpg         IPHICLUS SISTER\n",
      "4  test/Image_5.jpg  MILBERTS TORTOISESHELL\n"
     ]
    }
   ],
   "source": [
    "# Specify the full path to your model file\n",
    "model_path = 'butterfly_classifier_model.h5'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Model file '{model_path}' exists.\")\n",
    "else:\n",
    "    print(f\"Model file '{model_path}' does not exist.\")\n",
    "    exit(1)\n",
    "\n",
    "# Attempt to load the model\n",
    "\n",
    "\n",
    "try:\n",
    "    with h5py.File(model_path, 'r') as f:\n",
    "        model = tf.keras.models.load_model(f)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        try:\n",
    "            img = Image.open(filename)\n",
    "            img = img.resize((128, 128))  # Resize to a fixed size\n",
    "            images.append(np.array(img))  # Convert image to numpy array\n",
    "            filenames.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {filename}. Error: {e}\")\n",
    "    return images, filenames\n",
    "\n",
    "# Load the CSV file (assuming filenames are listed without labels)\n",
    "test_df = pd.read_csv('Testing_set.csv')\n",
    "\n",
    "# Load test images and filenames\n",
    "test_images, test_filenames = load_images(test_df)\n",
    "\n",
    "# Convert images to numpy array for further processing\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Normalize pixel values to [0, 1] range\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert predictions from numeric indices to butterfly species names\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = [list(label_mapping.keys())[list(label_mapping.values()).index(cls)] for cls in predicted_classes]\n",
    "\n",
    "# Add predicted labels to the DataFrame\n",
    "test_df['label'] = predicted_labels\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(test_df.head())\n",
    "\n",
    "# Save the updated CSV file with predicted labels\n",
    "test_df.to_csv('Testing_set_with_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
